{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Co-purchase Network\n",
    "This notebook contains the code for extracting and cleaning the amazon data.\n",
    "##### Note: The location of data files given here local to our machine. We have submitted files separately. In order to execute this notebook you need to copy those files and provide their location in the required places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All library imports\n",
    "import networkx as nx\n",
    "import csv\n",
    "from operator import itemgetter\n",
    "import community #This is the python-louvain package we installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "First of all the selected attributes are extraced from the metadata. Then the edgelist is created using a conversion function.\n",
    "Here it is shown for March data but has to be repeated for rest months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function extracts the list of atributes for each product\n",
    "# from the meta-data which we will be using for our analysis\n",
    "def extract_product_attributes_nodes(in_file,out_file):\n",
    "    #Read all lines of the meta data into content list.\n",
    "    fname = in_file #input metadata .txt file\n",
    "    with open(fname, encoding = 'utf8') as f:\n",
    "        content = f.readlines()\n",
    "    #Remove the beginning and trailing white spaces.\n",
    "    content = [x.strip() for x in content] \n",
    "\n",
    "    # Write extracted information to testfile.txt in a format of ',' demilited files.\n",
    "    # The columns are Id, title, group, categories, totalreviews, avgrating.\n",
    "    # The code stores all extracted information about a product into previoulines,\n",
    "    # and write the content into file only when all information are available. Hence,\n",
    "    # if review information for a product is not available, the product won't appear\n",
    "    # in the final file.\n",
    "   \n",
    "    file = open(out_file,\"w\", encoding='utf8') # output file with exracted attributes\n",
    "    previouslines = ['Id', 'title', 'group', 'categories', 'totalreviews', 'avgrating']\n",
    "    for line in content:\n",
    "        lines = line.split(':')\n",
    "        if lines[0] == \"Id\":\n",
    "            if (len(previouslines) == 6):\n",
    "                for component in previouslines[0:5]:\n",
    "                    file.write(component)\n",
    "                    file.write(',')\n",
    "                file.write(previouslines[5])\n",
    "                file.write(\"\\n\")\n",
    "            previouslines = []\n",
    "            previouslines.append(lines[1].strip())\n",
    "\n",
    "        if lines[0] == \"title\":\n",
    "            title = ':'.join(lines[1:]).strip().replace(',', ' ').replace('\\n', ' ').strip()\n",
    "            previouslines.append(title)\n",
    "\n",
    "        if lines[0] == \"group\":\n",
    "            previouslines.append(lines[1].strip())\n",
    "\n",
    "        if lines[0] == \"categories\":\n",
    "            previouslines.append(lines[1].strip())\n",
    "\n",
    "        if lines[0] == \"reviews\" and lines[1].strip() == \"total\":\n",
    "            previouslines.append(lines[2].split(' ')[1])\n",
    "            previouslines.append(lines[4].strip())\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Function converts the text file to .CSV file for creation of list of nodes and edges for the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function converts the text file to .CSV file for creation of list of nodes and edges for the graph\n",
    "def convert_txt_csv(i_file,o_file,final_csv):\n",
    "    with open(i_file, 'r', encoding='utf8', newline='') as in_file:\n",
    "        stripped = (line.strip() for line in in_file)\n",
    "        lines = (line.split(\",\") for line in stripped if line)\n",
    "        with open(o_file, 'w', encoding='utf8',newline='') as out_file:\n",
    "            writer = csv.writer(out_file)\n",
    "            writer.writerows(lines)\n",
    "    # read tab-delimited file\n",
    "    with open(o_file,'rt', encoding='utf8',newline='') as fin:\n",
    "        cr = csv.reader(fin, delimiter='\\t')\n",
    "        filecontents = [line for line in cr]\n",
    "\n",
    "    # write comma-delimited file (comma is the default delimiter)\n",
    "    with open(final_csv,'w', encoding='utf8',newline='') as fou:\n",
    "        cw = csv.writer(fou, quotechar='', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "        cw.writerows(filecontents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Invoke above defined functions\n",
    "extract_product_attributes_nodes('C:/Sushmita/MS DataScience/NetworkScience/Project/Data/amazon-meta/amazon-meta.txt',\n",
    "                                 'C:/Sushmita/MS DataScience/NetworkScience/Project/Results/graph/Amazon_March/testfile.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forms the edgelist for March\n",
    "convert_txt_csv('C:/Sushmita/MS DataScience/NetworkScience/Project/Results/graph/Amazon_March/edgelist.txt',\n",
    "                'C:/Sushmita/MS DataScience/NetworkScience/Project/Results/graph/Amazon_March/edgelist.tsv',\n",
    "                'C:/Sushmita/MS DataScience/NetworkScience/Project/Results/graph/Amazon_March/edgelist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Graph\n",
    "Using the nodelist and edgelist from above cells graph has to be created for each month. Again here we have done for only March."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function creates the graph based on the nodelist and edgelist created by above functions\n",
    "def create_graph(node_file,edge_file):\n",
    "    group_dict = {}\n",
    "    names_dict ={}\n",
    "    review_dict = {}\n",
    "    rating_dict ={}\n",
    "    G = nx.Graph()\n",
    "    with open(node_file, 'r',  encoding=\"utf8\",newline='') as nodecsv: # Open the file                       \n",
    "        nodereader = csv.reader(nodecsv) # Read the csv  \n",
    "        # Retrieve the data (using Python list comprhension and list slicing to remove the header row, see footnote 3)\n",
    "        nodes = [n for n in nodereader][1:]  \n",
    "    node_names = [n[0] for n in nodes]\n",
    "    with open(edge_file, 'r',  encoding=\"utf8\",newline='') as edgecsv: # Open the file\n",
    "        edgereader = csv.reader(edgecsv) # Read the csv     \n",
    "        edges = [tuple(e) for e in edgereader][1:] # Retrieve the data\n",
    "        \n",
    "    for node in nodes: # Loop through the list, one row at a time\n",
    "        names_dict[node[0]] = node[1]\n",
    "        group_dict[node[0]] = node[2]\n",
    "        review_dict[node[0]] = node[4]\n",
    "        rating_dict[node[0]] = node[5]\n",
    "        \n",
    "    \n",
    "    G.add_nodes_from(node_names)\n",
    "    G.add_edges_from(edges)\n",
    "    nx.set_node_attributes(G, names_dict, 'Title')\n",
    "    nx.set_node_attributes(G, group_dict, 'Group')\n",
    "    nx.set_node_attributes(G, review_dict, 'Reviews')\n",
    "    nx.set_node_attributes(G, rating_dict, 'AvgRating')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_March = create_graph('C:/Sushmita/MS DataScience/NetworkScience/Project/Results/graph/Amazon_March/testfile.txt',\n",
    "                    'C:/Sushmita/MS DataScience/NetworkScience/Project/Results/graph/Amazon_March/edgelist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "For better visualization isolates have been removed and large connected component has been extracted. Below shows for March and has to be repreated for other months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_list=list(nx.isolates(G_March))\n",
    "G_March.remove_nodes_from(remove_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import linkcom\n",
    "\n",
    "large_component=max(nx.connected_component_subgraphs(G_March), key=len)\n",
    "\n",
    "# Save the graph to file\n",
    "nx.write_gml(large_component, \"C:/Sushmita/MS DataScience/NetworkScience/Project/Results/graph/Amazon_March/march_large.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3.4]",
   "language": "python",
   "name": "conda-env-Anaconda3.4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
